package generation

import grammar._
import scala.util.Random


// TODO check where are branches that cannot generate words ?
case class ParsingTree[A](
  rTree: List[PrefixOperator with GrammarElement[A]],
  stack: List[StackTask[A]],
  prob: Double,
  refs: List[ParsingTree[A]],
  msgs: List[Message[A, _]]) { self =>

  import ParsingTree._


  lazy val wordSize: Int = rTree count {
    case Word(_) => true
    case _ => false
  }

  lazy val lastWord: Option[A] = rTree collectFirst { case Word(w) => w }

  val isClosed: Boolean = stack.isEmpty


  /** returns true if this tree can be closed without generating any word
    */
  lazy val nullable: Boolean = stack forall {
    case ge: GrammarElement[A] => ge.nullable
    case _ => true
  }

  /** returns the set of all possible next words generated by this tree,
    * considering it's known refinements
    */
  lazy val nextWords: Set[A] = {
    // collect firsts of nullable head of stack (eliminating messages)
    val nxtThis: Set[A] = (stack collect StackTask.grammElt span { _.nullable } match {
      case (nlb, hd::tail) => nlb :+ hd
      case (nlb, Nil) => nlb
    }).toSet flatMap { ge: GrammarElement[A] => ge.firsts }

    // compute intersection with refinements
    (nxtThis /: refs) { _ intersect _.nextWords }
  }

  /** nextWords of this as if e was added at top of stack
    */
  def nextWordsWith(e: GrammarElement[A]): Set[A] =
    if (e.nullable) e.firsts union nextWords
    else e.firsts


  lazy val getMessages: List[Message[A, _]] =
    (refs flatMap (_.getMessages)) ++ msgs

  lazy val dropMessages: ParsingTree[A] = self.updated(
    msgs = Nil,
    refs = refs map (_.dropMessages)
  )

  lazy val collectWords: List[A] = rTree.collect{case Word(w) => w}.reverse

  /** returns a list of parsing trees such that each one is
    * one word bigger and in a state where there is one single deterministic
    * step to generate a new word or closed.
    * Note that this function should not close a tree without generating a word.
    * For the first call, aka instantiation of parsing tree from grammar
    * the function prepareNexts should be called
    */
  def nexts(wishWord: A => Boolean): List[ParsingTree[A]] = {
    val words = nextWords filter wishWord
    normalize(
      elect(
        genNextWord(words) flatMap (_.prepareGen(Set(), true))
      ) { _.prob }
    )
  }

  /** generate one-step word from prepared state and adjust refinements
    * may be Nil if no refinement can generate the next word
    * may be longer if refinement has more than one way to generate
    * refinement
    * 
    * The self tree must be prepared to generate (otherwise: message shift)
    * 
    * Result Must be limited
    * ref grammars must be updated
    * 
    * sanity check: is it satisfiable ?
    * first: prepare grammars: Grammar must be in state ready to gen
    * a terminal
    */
  def genNextWord(wishWords: Set[A]): List[ParsingTree[A]] = {
    val words = self.nextWords intersect wishWords

    val size = self.wordSize

    def rejectTree(t: ParsingTree[A]): Boolean = {
      (words intersect t.nextWords).isEmpty
    }

    // accept tree if one word generated (should accept as soon as word generated
    def acceptTree(t: ParsingTree[A]): Boolean = t.wordSize == size + 1

    def acceptChild(e: GrammarElement[A], t: ParsingTree[A]): Boolean = {
      (t.nextWordsWith(e) intersect words).nonEmpty
    }

    // generator generates only acceptable Trees
    def generator(t: ParsingTree[A]): List[ParsingTree[A]] = {
      t.gen(rejectTree, acceptTree, acceptChild)
    }

    val mainGenerated: List[ParsingTree[A]] = rNexts(
      List(self),
      acceptTree(_),
      generator(_)
    )

    elect(mainGenerated flatMap (_.refNextWord(words)))(_.probWithRefHead)
  }


  def refHeadNextWord(wishWords: Set[A]): List[ParsingTree[A]] = {

    val words = nextWords intersect wishWords

    def generate(t: ParsingTree[A]): List[ParsingTree[A]] = {
      t.genNextWord(words)
    }

    genHeadRef(generate(_))
  }


  def refNextWord(wishWords: Set[A]): List[ParsingTree[A]] = {

    val words = wishWords intersect nextWords

    val generators: List[ParsingTree[A] => List[ParsingTree[A]]] =
      List.fill(refs.size)(_.refHeadNextWord(words))

    def probExtractor(t: ParsingTree[A]): Double = t.probWithRefHead

    boundMultiGen[ParsingTree[A]](List(self), generators, probExtractor(_))
  }

  /** Method called to put the tree where it is about to generate a
    * single terminal in a deterministic way
    * new approach : this is the key point. At each generation step,
    * the tree, additionnaly to the word generation will continue following
    * rules as far as possible, while no new word is generated and the
    * tree is still open
    * To ease the computation, don't forget to filter branches using firsts 
    *
    * 
    * highly probabale that closable will be always true
    */
  def prepareGen(wishWords: Set[A], closable: Boolean): List[ParsingTree[A]] = {

    val words = wishWords intersect nextWords

    
    def rejectTree(t: ParsingTree[A]): Boolean = {
      (words intersect t.nextWords).isEmpty &&
      !(t.nullable && closable)
    }

    // accept tree if ready to generate word of wishWords
    def acceptTree(t: ParsingTree[A]): Boolean = t.stack match {
      case Nil => closable
      case Word(w) :: tail =>  words contains w
      case _ => false
    }

    def acceptChild(e: GrammarElement[A], t: ParsingTree[A]): Boolean = {
      (t.nextWordsWith(e) intersect words).nonEmpty ||
      (e.nullable && t.nullable && closable)
    }

    // generator generates only acceptable Trees
    def generator(t: ParsingTree[A]): List[ParsingTree[A]] = {
      t.gen(rejectTree, acceptTree, acceptChild)
    }


    val mainReady: List[ParsingTree[A]] = rNexts(
      List(self),
      acceptTree(_),
      generator(_)
    )

    elect(mainReady flatMap (_.prepareRefs(words)))(_.probWithRefHead)
  }


  /** generates next step of search tree : List composed of parsing trees
    * that are accepted (solutions) and parsing tree about to make a non
    * deterministic step
    * refs grammars must be updated as well !
    */
  def gen(
    rejectTree: ParsingTree[A] => Boolean, // security
    acceptTree: ParsingTree[A] => Boolean,
    acceptChild: (GrammarElement[A], ParsingTree[A]) => Boolean
  ): List[ParsingTree[A]] =
    if (rejectTree(self)) Nil
    else if (acceptTree(self)) List(self)
    else stack match {
      case Nil => Nil // not accepted and nothing to change

      case Refine(g) :: stk => if (refs.size >= maxRefinements) Nil else {
        self.updated(
          stack = stk,
          refs = ParsingTree(g)::refs
        ).gen(rejectTree, acceptTree, acceptChild)
      }

      case (m: Message[A, _]) :: stk  =>
        self.updated(
          stack = stk,
          msgs = m::msgs
        ).gen(rejectTree, acceptTree, acceptChild)

      case (t: Terminal[A]) :: stk =>
        self.updated(
          rTree = t::rTree,
          stack = stk
        ).gen(rejectTree, acceptTree, acceptChild)

      case (r @ Rule(body)) :: stk =>
        self.updated(
          rTree = r :: rTree,
          stack = body ::: stk
        ).gen(rejectTree, acceptTree, acceptChild)

      case Production(rules) :: stk => {
        /* filter out unviable childrens (typically cannot generate expected words)
         * normalize weights to 1 for probability computation
         */
        val n = normalize(rules filter { x => acceptChild(x._1, self) }) { _._2 } { (x, y) => (x._1, y) }

        /* create childrens with probability relative to parent and filter out
         * unprobable ones
         */
        n collect { case (rule @ Rule(body), p) if (p*prob >= tresholdProb) =>
          self.updated(
            rTree = rule :: rTree,
            stack = body ::: stk,
            prob = prob*p)
        } flatMap {
          /* adding t.topStkIsProd to accept filter will cause recursion
           * to stop just before generating a production again
           */
          _.gen(rejectTree, t => acceptTree(t) || t.topStkIsProd, acceptChild)
        }
      }
    }


  def prepareHeadRef(wishWords: Set[A]): List[ParsingTree[A]] = {

    val words = nextWords intersect wishWords

    def generate(t: ParsingTree[A]): List[ParsingTree[A]] = {
      t.prepareGen(words, true)
    }

    genHeadRef(generate(_))
  }

  /** take all ref grammars and put them in a state where they are
    * ready to generate a new terminal in wishWords
    * (typically, nextWords of refined tree)
    */
  def prepareRefs(wishWords: Set[A]): List[ParsingTree[A]] = {

    val words = wishWords intersect nextWords

    // note that wishWords are systematically intersected with self.nextWords
    val generators: List[ParsingTree[A] => List[ParsingTree[A]]] =
      List.fill(refs.size)(_.prepareHeadRef(words))

    def probExtractor(t: ParsingTree[A]): Double = t.probWithRefHead

    boundMultiGen[ParsingTree[A]](List(self), generators, probExtractor(_))
  }

    /** applies a generate method to head of refinements and
    * return self.updated with each new refinement at tail of refs list
    * (for the sake of cyclic use of genHeadRef). If generated grammar is
    * closed, then do not reuse that gramar
    * 
    * result of generate method must be
    * normalized in probability
    * all childrens of generated refinement must respect
    * nullable || (nextWords intersect wishWords /*of parent*/).nonEmpty
    * 
    * 
    */
  def genHeadRef(
    generate: ParsingTree[A] => List[ParsingTree[A]]
  ): List[ParsingTree[A]] = refs match {
    case Nil => List(self)
    case r :: rs => generate(r) map {
      case newRef if newRef.isClosed => self.updated(refs = rs)
      case newRef /* !newRef.isClosed */ => self.updated(refs = rs :+ newRef)
    }
  }


  // builds a new open tree with updated specified values
  def updated(
    rTree: List[PrefixOperator with GrammarElement[A]] = rTree,
    stack: List[StackTask[A]] = stack,
    prob: Double = prob,
    refs: List[ParsingTree[A]] = refs,
    msgs: List[Message[A, _]] = msgs
  ): ParsingTree[A] = ParsingTree(rTree, stack, prob, refs, msgs)

  private lazy val topStkIsProd: Boolean = stack match {
    case Production(_) :: tail => true
    case _ => false
  }

  private lazy val probWithRefHead: Double = refs match {
    case Nil => self.prob
    case r :: rs => self.prob * r.prob
  }
}

object ParsingTree {
  val tresholdProb = 0.01
  val maxRefinements = 2
  val maxMemory = 10

  def normalize[A](target: List[A])(extract: A => Double)(update: (A, Double) => A): List[A] = {
    val total = (0.0 /: target) { _ + extract(_) }
    if (total <= 0) Nil else target map { t => update(t, extract(t)/total) }
  }


  def normalize[A](target: List[ParsingTree[A]]): List[ParsingTree[A]] =
    normalize[ParsingTree[A]](target) { _.prob } {
      case (tree, p2) => tree.updated(prob = p2)
    }

  def limit[A](target: List[A])(extract: A => Double): List[A] = {
    elect(target)(extract)
  }

  def elect[A](target: List[A])(extract: A => Double): List[A] =
    elect(maxMemory, target)(extract)

  def elect[A](count: Int, target: List[A])(extract: A => Double): List[A] = {
    Iterator.iterate[(List[A], List[A])]((Nil, target)) { case (result, target) =>
      val (elected, left) = electOne(target)(extract)
      (elected.toList ::: result, left)
    }.drop(count).next._1
  }

  def electOne[A](target: List[A])(extract: A => Double): (Option[A], List[A]) = {
    val total = target.foldLeft(0.0) { _ + extract(_) }
    val random = Random.nextDouble * total

    def r_elect(r: Double, l: List[A]): (Option[A], List[A]) = l match {
      case Nil => (None, Nil)
      case x :: xs => {
        val px = extract(x)
        // elects this one
        if (r < px) (Some(x), xs)
        // elects a following
        else {
          val (result, left) = r_elect(r - px, xs)
          (result, x :: left)
        }
      }
    }

    r_elect(random, target)
  }

  // must test that target is not null
  def chooseOne[A](target: List[A])(extract: A => Double): A = {
    // Error possible from here if targe == Nil
    electOne(target)(extract)._1.get
  }

  /** applies The algorithm.
    * Solutions is partitionned in valid solutions and pending solutions.
    * if pending is empty, return
    * pending solutions are flat mapped with generator => ps
    * valid solutions and ps are limited, then recursion
    */
  def rNexts[A](
    solutions: List[ParsingTree[A]],
    acceptTree: ParsingTree[A] => Boolean,
    generator: ParsingTree[A] => List[ParsingTree[A]]
  ): List[ParsingTree[A]] = solutions partition acceptTree match {
    case (sol, Nil) => sol
    case (sol, pen) => {
      val candidates = sol ::: (pen flatMap generator)
      rNexts(
        elect(candidates) { _.prob },
        acceptTree, generator
      )
    }

  }

  /** bounded multiple generations is similar to Iterator.iterate
    * a list of generation methods are provided, a probability extractor
    * and an initial list of solutions
    * while generators are not empty, generate for all solutions,
    * limit using probability extractor and recurse on tail of generators
    */

  def boundMultiGen[A](
    solutions: List[A],
    generators: List[A => List[A]],
    probExtractor: A => Double
  ): List[A] = generators match {
    case Nil => solutions
    case gen :: gens => boundMultiGen(
      elect(solutions flatMap gen)(probExtractor),
      gens, probExtractor
    )
  }


  def apply[A](ge: GrammarElement[A]): ParsingTree[A] = {
    ParsingTree(Nil, ge::Nil, 1, Nil, Nil)
  }

}
