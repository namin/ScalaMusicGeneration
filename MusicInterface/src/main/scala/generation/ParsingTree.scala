package generation

import grammar._
import scala.util.Random

sealed trait ParsingTree[A] { self =>
  val rTree: List[PrefixOperator with GrammarElement[A]]
  val prob: Double
  val msgs: List[Message[A, _]]

  lazy val wordSize: Int = rTree count {
    case Word(_) => true
    case _ => false
  }

  lazy val lastWord: Option[A] = rTree collectFirst { case Word(w) => w }

  /*
   * Closed trees accept everything, closed trees are accepted everywhere
   * Open trees accpet only open trees with same lastWord optional
   * Open trees with no lastword accept open trees with no lastword.
   */
  def accept(that: ParsingTree[A]): Option[ParsingTree[A]] = self match {
    // closed (main) Tree will not care anymore about refinements
    // approach here: main grammar may finish even if secondary not
    case ClosedTree(rT, p, m) => Some(that)
    case OpenTree(rT, s, p, r, m) => that match {
      case ClosedTree(rT, p, m) => Some(that)
      case _ => if (self.lastWord == that.lastWord) Some(that) else None
    }
  }

  def accept(thats: List[ParsingTree[A]]): List[ParsingTree[A]] =
    thats flatMap { self accept _ }

  /** returns a list of parsing trees such that each one is
    * one word bigger and in a state where there is one single deterministic
    * step to generate a new word or closed.
    * Note that this function should not close a tree without generating a word.
    * For the first call, aka instantiation of parsing tree from grammar
    * the function prepareNexts should be called
    */
  def nexts: List[ParsingTree[A]]



  def gen(
    acceptTree: ParsingTree[A] => Boolean,
    filterChilds: GrammarElement[A] => Boolean
  ): List[ParsingTree[A]]



  def candidatesNextWord: List[ParsingTree[A]] = ???


  def candidatesPrepare(wishWords: Set[A]): List[ParsingTree[A]] = ???

  /** returns true if this tree can be closed without generating any word
    */
  val nullable: Boolean

  /** returns the set of all possible next words generated by this tree,
    * considering it's known refinements
    */
  val nextWords: Set[A]

}

object ParsingTree {
  val tresholdProb = 0.01
  val maxRefinements = 2
  val maxMemory = 10

  def normalize[A](target: List[A])(extract: A => Double)(update: (A, Double) => A): List[A] = {
    val total = (0.0 /: target) { _ + extract(_) }
    if (total <= 0) Nil else target map { t => update(t, extract(t)/total) }
  }


  def normalize[A](target: List[ParsingTree[A]]): List[ParsingTree[A]] =
    normalize[ParsingTree[A]](target) { _.prob } {
      case (ClosedTree(rT, p1, m), p2) => ClosedTree(rT, p2, m)
      case (OpenTree(rT, s, p1, r, m), p2) => OpenTree(rT, s, p2, r, m)
    }

  def limit[A](target: List[A])(extract: A => Double): List[A] = {
    elect(maxMemory, target)(extract)
  }

  def elect[A](count: Int, target: List[A])(extract: A => Double): List[A] = {
    Iterator.iterate[(List[A], List[A])]((Nil, target)) { case (result, target) =>
      val (elected, left) = electOne(target)(extract)
      (elected.toList ::: result, left)
    }.drop(count).next._1
  }

  def electOne[A](target: List[A])(extract: A => Double): (Option[A], List[A]) = {
    val total = target.foldLeft(0.0) { _ + extract(_) }
    val random = Random.nextDouble * total

    def r_elect(r: Double, l: List[A]): (Option[A], List[A]) = l match {
      case Nil => (None, Nil)
      case x :: xs => {
        val px = extract(x)
        // elects this one
        if (r < px) (Some(x), xs)
        // elects a following
        else {
          val (result, left) = r_elect(r - px, xs)
          (result, x :: left)
        }
      }
    }

    r_elect(random, target)
  }

  /* c: candidate

  def nextGen[A](c: OpenTree[A]): List[ParsingTree[A]] = {
    c.nextsOneStep filterNot { _ == Failure })
  }
   */

}


case class ClosedTree[A](
  rTree: List[PrefixOperator with GrammarElement[A]],
  prob: Double,
  msgs: List[Message[A, _]])
    extends ParsingTree[A] { self =>

  def gen(
    acceptTree: ParsingTree[A] => Boolean,
    filterChilds: GrammarElement[A] => Boolean
  ): List[ParsingTree[A]] = if (acceptTree(self)) List(self) else Nil



  def nexts: List[ParsingTree[A]] = Nil
  val nullable: Boolean = true
  val nextWords: Set[A] = Set()
}


case class OpenTree[A](
  rTree: List[PrefixOperator with GrammarElement[A]],
  stack: List[Task[A]],
  prob: Double,
  refs: List[OpenTree[A]],
  msgs: List[Message[A, _]])
    extends ParsingTree[A] { self =>
  import ParsingTree._


  def gen(
    acceptTree: ParsingTree[A] => Boolean,
    acceptChild: GrammarElement[A] => Boolean
  ): List[ParsingTree[A]] = if (acceptTree(self)) List(self) else stack match {
    case Nil => self.close.gen(acceptTree, acceptChild)

    case Refine(g) :: stk => if (refs.size >= maxRefinements) Nil else {
      self.updated(stack = stk, refs = OpenTree(g)::refs).gen(acceptTree, acceptChild)
    }

    case (m: Message[A, _]) :: stk  =>
      self.updated(stack = stk, msgs = m::msgs).gen(acceptTree, acceptChild)

    case (t: Terminal[A]) :: stk =>
      self.updated(rTree = t::rTree, stack = stk).gen(acceptTree, acceptChild)

    case (r @ Rule(body)) :: stk =>
      self.updated(rTree = r :: rTree, stack = body ::: stk).gen(acceptTree, acceptChild)

    case Production(rules) :: stk => {
      /* filter out unviable childrens (typically cannot generate expected words)
       * normalize weights to 1 for probability computation
       */
      val n = normalize(rules filter { x => acceptChild(x._1) }) { _._2 } { (x, y) => (x._1, y) }

      /* create childrens with probability relative to parent and filter out
       * unprobable ones
       */
      n collect { case (rule @ Rule(body), p) if (p*prob >= tresholdProb) =>
        self.updated(
          rTree = rule :: rTree,
          stack = body ::: stk,
          prob = prob*p
        )
      }
    }
  }



  /* closed indicates : no terminal generated, tree closed
   * Success indicates : one terminal generated
   * Pending indicates : The choices of list need more steps to decide
   * Failure indicates : the constraints cannot be satisfied
   */
  private def oneGrammStep(
    accept: GrammarElement[A] => Boolean
  ): List[ParsingTree[A]] = stack match {
    case Nil => List(self.close)

    case Refine(g) :: stk =>
      // Indicates failure of applying this refinement
      if (refs.size >= maxRefinements) Nil
      else self.updated(stack = stk, refs = OpenTree(g)::refs).oneGrammStep(accept)

    case (m: Message[A, _]) :: stk  =>
      self.updated(stack = stk, msgs = m::msgs).oneGrammStep(accept)

    case (t: Terminal[A]) :: stk =>
      List(self.updated(rTree = t::rTree, stack = stk))

    case (r @ Rule(body)) :: stk =>
      List(self.updated(rTree = r :: rTree, stack = body ::: stk))

    case Production(rules) :: stk => {
      normalize(rules) { _._2 } { (x, y) => (x._1, y) } map { r =>
        val (rule @ Rule(body), p) = r
        self.updated(rTree = rule :: rTree, stack = body ::: stk, prob = prob*p)
      }
    }
  }

  private def prepareNext(
    accept: GrammarElement[A] => Boolean,
    tempSols: List[ParsingTree[A]]
  ): List[ParsingTree[A]] = stack match {
    case Nil => List(self.close)

    case Refine(g) :: stk =>
      // Indicates failure of applying this refinement
      if (refs.size >= maxRefinements) Nil
      else self.updated(stack = stk, refs = OpenTree(g)::refs).prepareNext(accept, tempSols)

    case (m: Message[A, _]) :: stk =>
      self.updated(stack = stk, msgs = m::msgs).prepareNext(accept, tempSols)

    case _ => ???

  }

  /* new approach : this is the key point. At each generation step,
   * the tree, additionnaly to the word generation will continue following
   * rules as far as possible, while no new word is generated and the
   * tree is still open
   * To ease the computation, don't forget to filter branches using firsts 
   */
  private def prepareNextWord(wishWords: Set[A]): List[ParsingTree[A]] = {
    stack match {
      case Nil => List(self.close) // closed
      case Word(w) :: stk => List(self) // good state, do not generate
      case _ => ??? //oneStackStep flatMap
    }
  }

  lazy val nullable: Boolean = stack forall {
    case ge: GrammarElement[A] => ge.nullable
    case _ => true
  }

  lazy val nextWords: Set[A] = {
    // collect firsts of nullable head of stack (eliminating messages)
    val nxtThis: Set[A] = (stack collect Task.grammElt span { _.nullable } match {
      case (nlb, hd::tail) => nlb :+ hd
      case (nlb, Nil) => nlb
    }).toSet flatMap { ge: GrammarElement[A] => ge.firsts }

    // compute intersection with refinements
    (nxtThis /: refs) { _ intersect _.nextWords }
  }



  /* new approach : next word will return the list of trees that exactly
   * generated one word and did not generate further.
   * this will be useful during the first generation (btw, prepareNextWord
   * could be used when creating a tree), but it has to return a list because
   * refinement trees may have multiple solution to generate the one word of
   * the main tree
   */
  /*
   * contract: next will either return open trees t' with :
   *   t.wordSize + 1 = t'.wordSize
   * or closed trees t'' with:
   *   t.wordSize = t'.wordSize + 1
   * 
   * Additionnaly, the size of returned list is limited to avoid complexity
   */
  def nexts: List[ParsingTree[A]] = {
    // find nexts for this tree
    // find nexts for each refinement trees
    // result is a ~join of lists on generated trees
    // join operation : closed tree match to any open tree
    // (special behavior closed left or right hand side)
    // join operation will limit breadth using probabilities
    self :: Nil
  }

  private def nextsMain: List[ParsingTree[A]] = ???/*self.oneGrammStep match {
    case Failure => Nil
    case Closed(tree) => List(tree)
    case Success(tree) => List(tree)
    case Pending(trees) => ??? /*limit(trees) flatMap _.oneGrammStep*/
  }*/

/*
  private def nextsMain_old: List[ParsingTree[A]] = {
    // limit with prob and not normalize here v
    val list = self.oneGrammStep
    val pending: List[OpenTree[A]] = list collect {
      case that: OpenTree[A] if that.wordSize + 1 == self.wordSize => that
    }
    val generated: List[ParsingTree[A]] = list filterNot { pending contains _ }

    // and add loop detection : compare next gen rule and probabilities
    generated ::: (pending flatMap { _.nextsMain })

  }
 */

  /** Returns all ParsingTrees with head of refinements evaluated,
    * accepted (else generated terminal equals last word of this or
    * refinements finishes) and put at the end of the refs list.
    * generated messages are lifted up to refined tree
    */
  private def refineHead: List[ParsingTree[A]] = refs match {
    case Nil => List(self)
    case h::t => normalize(self accept h.nexts) map {
      case ClosedTree(rT, p, m) =>
        self.updated(prob = prob * p, refs = t, msgs = m ::: msgs)
      case oT @ OpenTree(rT, s, p, r, m) =>
        self.updated(
          prob = prob * p,
          refs = t :+ oT.updated(msgs = Nil),
          msgs = oT.msgs ::: msgs)
    }
  }

  // builds a new open tree with updated specified values
  private def updated(
    rTree: List[PrefixOperator with GrammarElement[A]] = rTree,
    stack: List[Task[A]] = stack,
    prob: Double = prob,
    refs: List[OpenTree[A]] = refs,
    msgs: List[Message[A, _]] = msgs
  ): OpenTree[A] = OpenTree(rTree, stack, prob, refs, msgs)

/*
  def normalize(rules: List[(Rule[A], Double)]): List[(Rule[A], Double)] = {
    val total = rules.foldLeft(0.0)(_ + _._2)
    rules map { r => (r._1, r._2/total) }
  }
 */


  def close: ClosedTree[A] = ClosedTree(rTree, prob, msgs)

}

object OpenTree {
  def apply[A](ge: GrammarElement[A]): OpenTree[A] = {
    OpenTree(Nil, ge::Nil, 1, Nil, Nil)
  }
}
